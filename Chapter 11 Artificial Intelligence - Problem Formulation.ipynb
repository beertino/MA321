{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f727af",
   "metadata": {},
   "source": [
    "# Introduction to AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66abafe6",
   "metadata": {},
   "source": [
    "We call ourselves Homo sapiens—man the wise—because our **intelligence** is so important to\n",
    "us. For thousands of years, we have tried to understand how we think and act—that is, how\n",
    "our brain, a mere handful of matter, can perceive, understand, predict, and manipulate a\n",
    "world far larger and more complicated than itself. The field of **artificial intelligence**, or AI, is\n",
    "concerned with not just understanding but also building intelligent entities—machines that\n",
    "can compute how to act effectively and safely in a wide variety of novel situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cfb480",
   "metadata": {},
   "source": [
    "## What is AI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20c710",
   "metadata": {},
   "source": [
    "We build \"intelligent\" mechanisms that act like a human and think like a human,  to make computers solve human tasks **at least as good as a human but not necessarily in the way Humans do it**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9b1ce",
   "metadata": {},
   "source": [
    "## General Categories of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce62806f",
   "metadata": {},
   "source": [
    "**Narrow (Weak) AI** - Focus on solving a specific problem, e.g. navigating a maze, playing GO (Weiqi) game against a player.\n",
    "\n",
    "**General (Strong) AI** - Mechanisms that can solve many different problems, e.g. AI that can play MANY DIFFERENT games – refer to AlphaGo versus AlphaZero, refer to https://deepmind.com/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bd354",
   "metadata": {},
   "source": [
    "## Agent as AI Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d630b71",
   "metadata": {},
   "source": [
    "An **agent** is just something that acts, but computer agents are expected to do more: operate autonomously, perceive their environment, persist over a prolonged time period, adapt to change, and create and pursue goals. A **rational agent** is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome.\n",
    "\n",
    "Refer to the figure below for a visual of an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31170e2f",
   "metadata": {},
   "source": [
    "Let us understand these terminologies with the aid of an example - a *two-cell vacuum world*.\n",
    "\n",
    "In this problem, our objective is to move and use the vacuum agent to clean up both cells.\n",
    "\n",
    "<p><img alt=\"Python Cartoon\" src=\"https://drive.google.com/uc?id=1BgGs4lIipQIdMZ894JFNy_0JLSlF000H\" width = \"400\" align=\"center\" vspace=\"0px\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4e845",
   "metadata": {},
   "source": [
    "**Agents** are \"intelligent\" mechanisms that interact with an enviroment.\n",
    "- perceives environment data via **sensors**,\n",
    "- acts \"intelligently\" via **function**,\n",
    "- applies actions on environment via **actuators**.\n",
    "\n",
    "The focus of our module (MA321 -> MA421) is to build the **function** of a **(rational) agent**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2e1f1",
   "metadata": {},
   "source": [
    "# Solving AI Problems by Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f47d7",
   "metadata": {},
   "source": [
    "Many AI problems can be formulated and solved by searching algorithms. We will first learn how to formulate contextual problems into standard search problems. Later we will learn searching algorithms to solve them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec76a16",
   "metadata": {},
   "source": [
    "## Standarised Search Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ece4ea",
   "metadata": {},
   "source": [
    "A search problem can be defined formally with the following components: **state space/states**, **initial state**, **goal state(s)/goal function**, **actions**, **transition function**, and **cost function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56d45d",
   "metadata": {},
   "source": [
    "Let us understand these terminologies with the aid of an example - a *two-cell vacuum world*.\n",
    "\n",
    "In this problem, our objective is to move and use the vacuum agent to clean up both cells.\n",
    "\n",
    "<p><img alt=\"Python Cartoon\" src=\"https://drive.google.com/uc?id=1XKmZpRTo3M-5MGNpobk5jGhwrlAVAcvS\" width = \"600\" align=\"center\" vspace=\"0px\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcdabd",
   "metadata": {},
   "source": [
    "**State** ($s$): an **abstraction/representation** of the environment.\n",
    "\n",
    "**State space** ($S$): the set of all the possible states. $S=\\{s_0, s_1, s_2, s_3, ..., s_n\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e633e035",
   "metadata": {},
   "source": [
    "There are many ways to abstract/represent the environment. One possible way is to use a tuple `(loc, cells)`, where\n",
    "- `loc` represents the location of the agent. It is equal to 0 if the agent is in the first (left) cell or 1 if the agent is in the second (right) cell.\n",
    "- `cells` is a list (of two items in this case) representing the status of the cells, each item can be either 0 (for a cell without dirts) or 1 (for a cell with dirts).\n",
    "\n",
    "There are a total of 8 possible **states** in the **state space**, they are (in the order of the figure)\n",
    "```python\n",
    "(0, [1, 1])\n",
    "(1, [1, 1])\n",
    "(0, [0, 1])\n",
    "(1, [0, 1])\n",
    "(0, [1, 0])\n",
    "(1, [1, 0])\n",
    "(0, [0, 0])\n",
    "(1, [0, 0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196d2ce",
   "metadata": {},
   "source": [
    "**Example 11.1**\n",
    "\n",
    "Find and describe a different way to abstract the environment. List the 8 states in the state space based on the proposed method of abstraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb257d30",
   "metadata": {},
   "source": [
    "*Describe your abstraction method below*\n",
    "\n",
    "*List the 8 states based on this abstraction method*\n",
    "```python\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac6e2e",
   "metadata": {},
   "source": [
    "**Discuss:**\n",
    "\n",
    "1. How many states are there in a n-cell vacuum world?\n",
    "2. How to adapt the given method of abstraction to a n-cell vacuum world?\n",
    "3. How easy it is to adapt your method of abstraction to a n-cell vacuum world?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b463dad",
   "metadata": {},
   "source": [
    "**Initial state** ($s_0$): starting state of the environment.\n",
    "\n",
    "**Goal state**: the state or the set of states that satisfies the environment conditions that we wish the agent to achieve.\n",
    "\n",
    "**Goal test** ($G$): a function $G$, such that $G(s_i)$ allows us to determine if $s_i$ is a goal state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f45747",
   "metadata": {},
   "source": [
    "In the two-cell vacuum world, any state can be designated as the initial state, e.g. `(1, [1, 1])`.\n",
    "\n",
    "The goal states are those in which every cell is clean, i.e. `(0, [0, 0])` and `(1, [0, 0])`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a68b4",
   "metadata": {},
   "source": [
    "**Example 11.2**\n",
    "\n",
    "Write the goal test function for the two-cell vaccum world. The function `goal_test()`\n",
    "- takes in a state in the form `loc, cells` as described above.\n",
    "- returns `True` if the state is a goal state; `False` otherwise.\n",
    "\n",
    "*Test cases:*\n",
    "```python\n",
    "goal_test(0, [1, 0]) should return False\n",
    "goal_test(1, [0, 0]) should return True\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ff75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3dba1b",
   "metadata": {},
   "source": [
    "**Actions** ($A$): a function $A$, such that $A(s_i)$ returns the actions that may be taken at state $s_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4da339",
   "metadata": {},
   "source": [
    "In the two-cell vacuum world, there are 3 possible actions: suck (S), move left (L), and move right (R). However, some of the actions will not be applicable for a given state - for example, the action S is not applicable to the state `(1, [1, 0])` and the action L is not applicable to the state `(0, [1, 1])`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c99abdd",
   "metadata": {},
   "source": [
    "**Example 11.3**\n",
    "\n",
    "Write the actions function for the two-cell vacuum world. The function `get_actions()`\n",
    "- takes in a state in the form `loc, cells` as described above,\n",
    "- returns the list of possible actions \"S\", \"L\" and \"R\" for the state.\n",
    "\n",
    "*Test cases:*\n",
    "```python\n",
    "get_actions(0, [1, 1]) should return ['S', 'R']\n",
    "get_actions(1, [1, 1]) should return ['S', 'L']\n",
    "get_actions(0, [0, 1]) should return ['R']\n",
    "get_actions(1, [0, 1]) should return ['S', 'L']\n",
    "get_actions(0, [1, 0]) should return ['S', 'R']\n",
    "get_actions(1, [1, 0]) should return ['L']\n",
    "get_actions(0, [0, 0]) should return ['R']\n",
    "get_actions(1, [0, 0]) should return ['L']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794cc6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e3ee90",
   "metadata": {},
   "source": [
    "In a two-dimensional multi-cell world we need more movement actions. We could add upward (U) and Downward (D), give us four **absolute** movement actions, or we could switch to **egocentric actions**, defined relative to the viewpoint of the agent - for example, *Forward*, *Backward*, *TurnRight*, and *TurnLeft*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0326e6",
   "metadata": {},
   "source": [
    "**Transition** ($T$): a function $T$, such that $T(s_i, a_k)\\rightarrow s_j$, where $s_j$ corresponds to the resultant state when applying action $a_k$ in state $s_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7087d4a",
   "metadata": {},
   "source": [
    "Here are some examples of transitions in the two-cell vacuum world. When we apply the action `\"L\"` in state `(1, [0, 1])`, the resultant state is `(0, [0, 1])`; when we apply `\"S\"` in `(1, [0, 1])`, the resultant state is `(1, [0, 0])`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a27d1",
   "metadata": {},
   "source": [
    "**Example 11.4**\n",
    "\n",
    "Write the transition function for the two-cell vacuum world. The function `transition()`,\n",
    "- takes in a state and an action to be applied at this state, in the form `loc`, `cells`, `act`,\n",
    "- returns the resultant state in the form `new_loc`, `new_cells`.\n",
    "\n",
    "Note that you need not worry about whether the action is \"executable\".\n",
    "\n",
    "*Test cases:*\n",
    "```python\n",
    "transition(1, [0, 1], \"L\") should return (0, [0, 1])\n",
    "transition(1, [0, 1], \"S\") should return (1, [0, 0])\n",
    "transition(0, [1, 1], \"R\") should return (1, [1, 1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98638692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9481336",
   "metadata": {},
   "source": [
    "**Action Cost** ($C$): a function $C$, such that $C(s_i, a_k, s_j)\\rightarrow cost$, which is the numeric cost of applying action $a_k$ in state $s_i$ to reach $s_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079142a",
   "metadata": {},
   "source": [
    "In the two-cell vacuum world, the cost can be set as uniform, i.e. moving left, right or sucking has the same cost which can be set as 1. See the action cost function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02489000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_cost(loc, cells, act, new_loc, new_cells):\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6bfcec",
   "metadata": {},
   "source": [
    "You may also differentiate the cost for different actions in the formulation process if the problem says otherwise. \n",
    "In general, the problem-solving agent should use a cost function that reflects its own performance measure. For example, a route-finding agent may have a cost function that reflects the distance or the time taken to travel from one state to another. We will learn how to explore such problems in a later lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c067f7",
   "metadata": {},
   "source": [
    "<p><img alt=\"Python Cartoon\" src=\"https://drive.google.com/uc?id=17qx7WNiRa-JOtgCgHWPtDZ7RkmwaaUDu\" width = \"100\" align=\"left\" vspace=\"0px\"></p>\n",
    "\n",
    "# *Go to Assignment 11A*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f0200",
   "metadata": {},
   "source": [
    "# Formulating Search Problems with Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0741e9",
   "metadata": {},
   "source": [
    "Recall that search problem can be defined formally with the following components: **state space/states**, **initial state**, **goal state(s)/goal function**, **actions**, **transition function**, and **cost function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b50856",
   "metadata": {},
   "source": [
    "We have seen a few examples involving no cost for actions (we can set the cost to be 1). In solving some AI problems, **route-finding** problems for example, we need to set different costs in the formulation to enable us to find an optimal solution later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5090b671",
   "metadata": {},
   "source": [
    "## Route-finding Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d8c21",
   "metadata": {},
   "source": [
    "Let us look at a travel problem as an example. The figure below is an simplified road map of part of Romania, with road distances in miles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d5b7d",
   "metadata": {},
   "source": [
    "<p><img alt=\"Romania Map Full\" src=\"https://drive.google.com/uc?id=1VKQq1VIISEzrPSEV-LZHaImpGmuqoVc-\" width = \"640\" align=\"left\" vspace=\"0px\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e282f",
   "metadata": {},
   "source": [
    "Suppose that we want AI to help us find the **shortest** path from Arad to Bucharest, then we need to formulate the problem first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b3dfc",
   "metadata": {},
   "source": [
    "**State** ($s$): an **abstraction/representation** of the environment.\n",
    "\n",
    "**State space** ($S$): the set of all the possible states. $S=\\{s_0, s_1, s_2, s_3, ..., s_n\\}$.\n",
    "\n",
    "**Initial state** ($s_0$): starting state of the environment.\n",
    "\n",
    "**Goal state**: the state or the set of states that satisfies the environment conditions that we wish the agent to achieve.\n",
    "\n",
    "**Goal test** ($G$): a function $G$, such that $G(s_i)$ allows us to determine if $s_i$ is a goal state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4baba3",
   "metadata": {},
   "source": [
    "**Example 11.5 (state, intial state, goal state and goal test)**\n",
    "\n",
    "One possible state space, saving the first letters of the city names, is given below:\n",
    "```\n",
    "state_space = [\n",
    "    \"A\", \"B\", \"C\", \"D\",\n",
    "    \"E\", \"F\", \"G\", \"H\",\n",
    "    \"I\", \"L\", \"M\", \"N\",\n",
    "    \"O\", \"P\", \"R\", \"S\",\n",
    "    \"T\", \"U\", \"V\", \"Z\"]\n",
    "```\n",
    "Assign initial and goal states `initial_state` and `goal_state`.\n",
    "\n",
    "Then write the goal test function `goal_test()` which\n",
    "- takes in a state,\n",
    "- return `True` if the state is the goal state; `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af7abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space = [\n",
    "    \"A\", \"B\", \"C\", \"D\",\n",
    "    \"E\", \"F\", \"G\", \"H\",\n",
    "    \"I\", \"L\", \"M\", \"N\",\n",
    "    \"O\", \"P\", \"R\", \"S\",\n",
    "    \"T\", \"U\", \"V\", \"Z\"]\n",
    "\n",
    "#set initial and goal states\n",
    "\n",
    "#def the goal test function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f43c0",
   "metadata": {},
   "source": [
    "**Actions** ($A$): a function $A$, such that $A(s_i)$ returns the actions that may be taken at state $s_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219e037",
   "metadata": {},
   "source": [
    "**Example 11.6 (actions)**\n",
    "\n",
    "To formulate travel problems as such, we may denote an action by *ToDestination* or *->Destination*. For example, all the possible actions are saved in this list.\n",
    "\n",
    "```python\n",
    "action_space = [\n",
    "    \"->A\", \"->B\", \"->C\", \"->D\",\n",
    "    \"->E\", \"->F\", \"->G\", \"->H\",\n",
    "    \"->I\", \"->L\", \"->M\", \"->N\",\n",
    "    \"->O\", \"->P\", \"->R\", \"->S\",\n",
    "    \"->T\", \"->U\", \"->V\", \"->Z\"]\n",
    "```\n",
    "\n",
    "Write the actions function, `get_actions()`, which\n",
    "- takes in a state\n",
    "- returns the list of possible actions at this state.\n",
    "\n",
    "*Test cases:*\n",
    "```python\n",
    "get_actions(\"A\") should return ['->S', '->T', '->Z']\n",
    "get_actions(\"B\") should return ['->F', '->G', '->P', '->U']\n",
    "get_actions(\"N\") should return ['->I']\n",
    "get_actions(\"Z\") should return ['->A', '->O']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab7a9c",
   "metadata": {},
   "source": [
    "Instead of using a long series of `if`, `elif` or `else` to code this part, we may make use a `dictionary` to simplify the process. A `dictionary` is similar to a `list`. The main difference is that an item in a `list` is referenced by its **index** while an item in a `dictionary` is referenced by its **key**. Run the following code cells to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_A = [\"John\", 1.78, 72.4] # a list storing a person's name, height and weight\n",
    "print(person_A[0])\n",
    "print(person_A[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4557c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_B = {\"name\": \"Alex\", \"height\": 1.81, \"weight\": 79.5} # a dictionary storing a person's name, height and weight\n",
    "print(person_B[\"name\"]) # the key \"name\" is used as the reference instead of index 0\n",
    "print(person_B[\"height\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554e124",
   "metadata": {},
   "source": [
    "For a more complete learning of the data type `dictionary`, refer to [link]. Now we are ready to code this example, but **fill up the missing pieces** first before running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf82632",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = [\n",
    "    \"->A\", \"->B\", \"->C\", \"->D\",\n",
    "    \"->E\", \"->F\", \"->G\", \"->H\",\n",
    "    \"->I\", \"->L\", \"->M\", \"->N\",\n",
    "    \"->O\", \"->P\", \"->R\", \"->S\",\n",
    "    \"->T\", \"->U\", \"->V\", \"->Z\"]\n",
    "\n",
    "state_actions = {\n",
    "        \"A\": [\"->S\", \"->T\", \"->Z\"],\n",
    "        \"B\": [\"->F\", \"->G\", \"->P\", \"->U\"],\n",
    "        \"C\": [\"->D\", \"->P\", \"->R\"], \n",
    "        \"D\": [\"->C\", \"->M\"],\n",
    "        \"E\": [\"->H\"],\n",
    "        \"F\": [\"->B\", \"->S\"],\n",
    "        \"G\": [\"->B\"],\n",
    "        \"H\": [\"->E\", \"->U\"],\n",
    "        \"I\": [\"->N\", \"->V\"],\n",
    "        \"L\": [\"->M\", \"->T\"],\n",
    "        \"M\": [\"->D\", \"->L\"],\n",
    "        \"N\": # missing piece\n",
    "        \"O\": [\"->S\", \"->Z\"],\n",
    "        \"P\": [\"->B\", \"->C\", \"->R\"],\n",
    "        \"R\": [\"->C\", \"->P\", \"->S\"],\n",
    "        \"S\": # missing piece\n",
    "        \"T\": [\"->A\", \"->L\"],\n",
    "        # missing piece\n",
    "        \"V\": [\"->I\", \"->U\"],\n",
    "        # missing piece\n",
    "        }\n",
    "\n",
    "def get_actions(s):\n",
    "    \n",
    "    # make use of the dictionary above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2bb4c0",
   "metadata": {},
   "source": [
    "**Transition** ($T$): a function $T$, such that $T(s_i, a_k)\\rightarrow s_j$, where $s_j$ corresponds to the resultant state when applying action $a_k$ at the state $s_i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f55930",
   "metadata": {},
   "source": [
    "**Example 11.7 (transition)**\n",
    "\n",
    "Write the transition function for the travelling problem. The function `transition()`,\n",
    "- takes in a state and an action to be applied at this state,\n",
    "- returns the resultant state.\n",
    "\n",
    "Note that you need not worry about whether the action is \"executable\".\n",
    "\n",
    "*Test cases:*\n",
    "```python\n",
    "transition(\"A\", \"->T\") should return 'T'\n",
    "transition(\"B\", \"->U\") should return 'U'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba09e5d",
   "metadata": {},
   "source": [
    "**Action Cost** ($C$): a function $C$, such that $C(s_i, a_k, s_j)\\rightarrow cost$, which is the numeric cost of applying action $a_k$ in state $s_i$ to reach $s_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248cd6f6",
   "metadata": {},
   "source": [
    "**Example 11.8 (action cost)**\n",
    "\n",
    "Write the action cost function for the travelling problem. The function `action_cost()`\n",
    "- takes in the old state, the action and the new state,\n",
    "- returns the cost (distance in miles).\n",
    "\n",
    "*Test cases:*\n",
    "```python\n",
    "action_cost(\"A\", \"->S\", \"S\") should return 140\n",
    "action_cost(\"G\", \"->B\", \"B\") should return 90\n",
    "action_cost(\"P\", \"->C\", \"C\") should return 138\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802b5b3",
   "metadata": {},
   "source": [
    "In this example, we may use a list to store the distances in miles between two cities. Each item contains the old state, the new state and the cost as a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_costs = [\n",
    "    (\"A\", \"S\", 140), (\"A\", \"T\", 118), # missing piece,\n",
    "    (\"B\", \"F\", 211), (\"B\", \"G\", 90),  (\"B\", \"P\", 101), (\"B\", \"U\", 85),\n",
    "    (\"C\", \"D\", 120), (\"C\", \"P\", 138), (\"C\", \"R\", 146),\n",
    "    (\"D\", \"C\", 120), (\"D\", \"M\", 75),\n",
    "    (\"E\", \"H\", 86),\n",
    "    (\"F\", \"B\", 211), (\"F\", \"S\", 99),\n",
    "    (\"G\", \"B\", 90),\n",
    "    (\"H\", \"E\", 86),  (\"H\", \"U\", 98),\n",
    "    (\"I\", \"N\", 87),  (\"I\", \"V\", 92),\n",
    "    (\"L\", \"M\", 70),  (\"L\", \"T\", 111),\n",
    "    (\"M\", \"D\", 75),  (\"M\", \"L\", 70),\n",
    "    (\"N\", \"I\", 87),\n",
    "    # missing piece, # missing piece,\n",
    "    (\"P\", \"B\", 101), (\"P\", \"C\", 138), (\"P\", \"R\", 97),\n",
    "    (\"R\", \"C\", 146), (\"R\", \"P\", 97),  (\"R\", \"S\", 80),\n",
    "    (\"S\", \"A\", 140), (\"S\", \"F\", 99),  (\"S\", \"O\", 151), (\"S\", \"R\", 80),\n",
    "    (\"T\", \"A\", 118), (\"T\", \"L\", 111),\n",
    "    (\"U\", \"B\", 85),  (\"U\", \"H\", 98),  (\"U\", \"V\", 142),\n",
    "    (\"V\", \"I\", 92),  (\"V\", \"U\", 142),\n",
    "    (\"Z\", \"A\", 75),  # missing piece\n",
    "]\n",
    "\n",
    "def action_cost(old_s, a, new_s):\n",
    "    \n",
    "    # make use of the list above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237d6b1",
   "metadata": {},
   "source": [
    "Apart from finding the shortest path from one city to another (e.g. from Arad to Bucharest), some other possible problems include\n",
    "- finding the shortest path if certain cities must be visited (e.g. from Arad to Bucharest, visiting Craiova and Fagaras,\n",
    "- finding the shortest path if one person wants to visits each city exactly once and returns to the origin city (travelling salesman problem, TSP),\n",
    "- finding the set paths that connect all the cities with the minimum total distance (the minimal spanning tree, MST)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16588d79",
   "metadata": {},
   "source": [
    "We will learn the algorithms to solve some the these problems next year. Meanwhile, the code at the end of the lesson give you the solution to the shortest path from Arad to Bucharest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe9201",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e98f9d",
   "metadata": {},
   "source": [
    "To formulate a AI problem which can be solved by searching algorithms, we need the following components:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8315cf7",
   "metadata": {},
   "source": [
    "**State** ($s$): an **abstraction/representation** of the environment.\n",
    "\n",
    "**State space** ($S$): the set of all the possible states. $S=\\{s_0, s_1, s_2, s_3, ..., s_n\\}$.\n",
    "\n",
    "**Initial state** ($s_0$): starting state of the environment.\n",
    "\n",
    "**Goal state**: the state or the set of states that satisfies the environment conditions that we wish the agent to achieve.\n",
    "\n",
    "**Goal test** ($G$): a function $G$, such that $G(s_i)$ allows us to determine if $s_i$ is a goal state.\n",
    "\n",
    "**Actions** ($A$): a function $A$, such that $A(s_i)$ returns the actions that may be taken at state $s_i$.\n",
    "\n",
    "**Transition** ($T$): a function $T$, such that $T(s_i, a_k)\\rightarrow s_j$, where $s_j$ corresponds to the resultant state when applying action $a_k$ at the state $s_i$.\n",
    "\n",
    "**Action Cost** ($C$): a function $C$, such that $C(s_i, a_k, s_j)\\rightarrow cost$, which is the numeric cost of applying action $a_k$ in state $s_i$ to reach $s_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c935c4",
   "metadata": {},
   "source": [
    "<p><img alt=\"Python Cartoon\" src=\"https://drive.google.com/uc?id=17qx7WNiRa-JOtgCgHWPtDZ7RkmwaaUDu\" width = \"100\" align=\"left\" vspace=\"0px\"></p>\n",
    "\n",
    "# *Go to Assignment 11B*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd21cc",
   "metadata": {},
   "source": [
    "# Solutions to Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81605a03",
   "metadata": {},
   "source": [
    "**Example 11.2 Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220adec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_test(loc, cells):\n",
    "    \n",
    "    return cells[0] == 0 and cells[1] == 0\n",
    "#   for a n-cell vacuum world\n",
    "#   return sum(cells) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d41edb",
   "metadata": {},
   "source": [
    "**Example 11.3 Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions(loc, cells):\n",
    "    \n",
    "    actions = [\"S\", \"L\", \"R\"]\n",
    "    \n",
    "    if loc == 0:\n",
    "        actions.remove(\"L\")\n",
    "    \n",
    "    if loc == len(cells) - 1:\n",
    "        actions.remove(\"R\")\n",
    "        \n",
    "    if cells[loc] == 0:\n",
    "        actions.remove(\"S\")\n",
    "        \n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c1bd4",
   "metadata": {},
   "source": [
    "**Example 11.4 Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(loc, cells, act):\n",
    "    \n",
    "    new_cells = cells.copy()\n",
    "    \n",
    "    if act == \"S\":\n",
    "        new_loc = loc\n",
    "        new_cells[loc] = 0\n",
    "        \n",
    "    if act == \"L\":\n",
    "        new_loc = loc - 1\n",
    "    \n",
    "    if act == \"R\":\n",
    "        new_loc = loc + 1\n",
    "    \n",
    "    return new_loc, new_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0755c",
   "metadata": {},
   "source": [
    "**Example 11.5 Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space = [\n",
    "    \"A\", \"B\", \"C\", \"D\",\n",
    "    \"E\", \"F\", \"G\", \"H\",\n",
    "    \"I\", \"L\", \"M\", \"N\",\n",
    "    \"O\", \"P\", \"R\", \"S\",\n",
    "    \"T\", \"U\", \"V\", \"Z\"]\n",
    "\n",
    "initial_state = \"A\"\n",
    "goal_state = \"B\"\n",
    "\n",
    "def goal_test(s):\n",
    "    \n",
    "    return s == goal_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ca2ea",
   "metadata": {},
   "source": [
    "**Example 11.6 Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba572e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = [\n",
    "    \"->A\", \"->B\", \"->C\", \"->D\",\n",
    "    \"->E\", \"->F\", \"->G\", \"->H\",\n",
    "    \"->I\", \"->L\", \"->M\", \"->N\",\n",
    "    \"->O\", \"->P\", \"->R\", \"->S\",\n",
    "    \"->T\", \"->U\", \"->V\", \"->Z\"]\n",
    "\n",
    "state_actions = {\n",
    "        \"A\": [\"->S\", \"->T\", \"->Z\"],\n",
    "        \"B\": [\"->F\", \"->G\", \"->P\", \"->U\"],\n",
    "        \"C\": [\"->D\", \"->P\", \"->R\"], \n",
    "        \"D\": [\"->C\", \"->M\"],\n",
    "        \"E\": [\"->H\"],\n",
    "        \"F\": [\"->B\", \"->S\"],\n",
    "        \"G\": [\"->B\"],\n",
    "        \"H\": [\"->E\", \"->U\"],\n",
    "        \"I\": [\"->N\", \"->V\"],\n",
    "        \"L\": [\"->M\", \"->T\"],\n",
    "        \"M\": [\"->D\", \"->L\"],\n",
    "        \"N\": [\"->I\"],\n",
    "        \"O\": [\"->S\", \"->Z\"],\n",
    "        \"P\": [\"->B\", \"->C\", \"->R\"],\n",
    "        \"R\": [\"->C\", \"->P\", \"->S\"],\n",
    "        \"S\": [\"->A\", \"->F\", \"->O\", \"->R\"],\n",
    "        \"T\": [\"->A\", \"->L\"],\n",
    "        \"U\": [\"->B\", \"->H\", \"->V\"],\n",
    "        \"V\": [\"->I\", \"->U\"],\n",
    "        \"Z\": [\"->A\", \"->O\"]}\n",
    "\n",
    "def get_actions(s):\n",
    "    \n",
    "    return state_actions[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f1a66",
   "metadata": {},
   "source": [
    "**Example 11.7 Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccdafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(s, a):\n",
    "    \n",
    "    return a[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1ddb6",
   "metadata": {},
   "source": [
    "**Example 11.8 Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea20cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_costs = [\n",
    "    (\"A\", \"S\", 140), (\"A\", \"T\", 118), (\"A\", \"Z\", 75),\n",
    "    (\"B\", \"F\", 211), (\"B\", \"G\", 90),  (\"B\", \"P\", 101), (\"B\", \"U\", 85),\n",
    "    (\"C\", \"D\", 120), (\"C\", \"P\", 138), (\"C\", \"R\", 146),\n",
    "    (\"D\", \"C\", 120), (\"D\", \"M\", 75),\n",
    "    (\"E\", \"H\", 86),\n",
    "    (\"F\", \"B\", 211), (\"F\", \"S\", 99),\n",
    "    (\"G\", \"B\", 90),\n",
    "    (\"H\", \"E\", 86),  (\"H\", \"U\", 98),\n",
    "    (\"I\", \"N\", 87),  (\"I\", \"V\", 92),\n",
    "    (\"L\", \"M\", 70),  (\"L\", \"T\", 111),\n",
    "    (\"M\", \"D\", 75),  (\"M\", \"L\", 70),\n",
    "    (\"N\", \"I\", 87),\n",
    "    (\"O\", \"S\", 151), (\"O\", \"Z\", 71),\n",
    "    (\"P\", \"B\", 101), (\"P\", \"C\", 138), (\"P\", \"R\", 97),\n",
    "    (\"R\", \"C\", 146), (\"R\", \"P\", 97),  (\"R\", \"S\", 80),\n",
    "    (\"S\", \"A\", 140), (\"S\", \"F\", 99),  (\"S\", \"O\", 151), (\"S\", \"R\", 80),\n",
    "    (\"T\", \"A\", 118), (\"T\", \"L\", 111),\n",
    "    (\"U\", \"B\", 85),  (\"U\", \"H\", 98),  (\"U\", \"V\", 142),\n",
    "    (\"V\", \"I\", 92),  (\"V\", \"U\", 142),\n",
    "    (\"Z\", \"A\", 75),  (\"Z\", \"O\", 71)]\n",
    "\n",
    "def action_cost(old_s, a, new_s):\n",
    "    \n",
    "    for item in action_costs:\n",
    "        \n",
    "        if item[0] == old_s and item[1] == new_s:\n",
    "            return item[2]\n",
    "    \n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
